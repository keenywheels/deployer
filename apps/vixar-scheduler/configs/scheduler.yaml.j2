scheduler:
  cron_pattern: "{{ app.scheduler.cron_pattern }}"
  workers_count: {{ app.scheduler.workers_count }}
  logger:
    loglvl: info
    mode: production
    encoding: json
  system_server:
    enabled: {{ app.system_server.enabled }}
    port: {{ app.system_server.port }}
  scraper:
    output_every: {{ app.scraper.output_every }}
    log_errors: {{ app.scraper.log_errors }}
    max_depth: {{ app.scraper.max_depth }}
    filter_pattern: "{{ app.scraper.filter_pattern }}"
    tags_to_parse: {{ app.scraper.tags_to_parse }}
    is_async: {{ app.scraper.is_async }}
    # async_delay: 3s
    # async_request_limit: 5
    user_agent: "{{ app.scraper.user_agent }}"
    headers:
      User-Agent: "{{ app.scraper.headers.user_agent }}"
      Accept: "{{ app.scraper.headers.accept }}"
      Accept-Language: "{{ app.scraper.headers.accept_language }}"
      Accept-Encoding: "{{ app.scraper.headers.accept_encoding }}"
      Connection: "{{ app.scraper.headers.connection }}"
    queue:
      enabled: {{ app.scraper.queue.enabled }}
      thread_number: {{ app.scraper.queue.thread_number }}
      max_size: {{ app.scraper.queue.max_size }}
  sites:
{% for site in app.sites %}
    - name: "{{ site.name }}"
      url: "{{ site.url }}"
      category: "{{ site.category }}"
{% endfor %}

kafka:
  max_retry: {{ app.kafka.max_retry }}
  topics:
    scraper_data: "{{ app.kafka.topic }}"
  brokers:
  {% for broker in app.kafka.brokers %}
  - {{ broker }}
  {% endfor %}
